{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcbfdd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import zenml\n",
    "# import databricks.koalas as ks\n",
    "# from databricks.mlflow.client import MlflowClient\n",
    "# from databricks.mlflow.types import Schema\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2a8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "with open('C:/Users/vijaya.sekhar/Downloads/download/download/EVRI/EVRI/data/evri-nonprod-dgw-firehose-tracking-5-2022-05-05-06 (early morning sample).json') as f:\n",
    "        ps_data = json.load(f)\n",
    "ps_df = pd.json_normalize(ps_data)\n",
    "df = ps_df[['originalParcelCreationTime',\n",
    "   'trackingEvent.eventCategory',\n",
    "  'trackingEvent.client.clientId',\n",
    "   'trackingEvent.preadviceDetail.deliveryDetails.parcelId',\n",
    "   'trackingEvent.preadviceDetail.parcelDetails.numberOfItems',\n",
    "   'trackingEvent.preadviceDetail.parcelType.parcelTypeId']].copy()\n",
    "        \n",
    "df[\"originalParcelCreationTime\"]= pd.to_datetime(df[\"originalParcelCreationTime\"])\n",
    "df['hour'] = df[\"originalParcelCreationTime\"].dt.hour\n",
    "df['weekdayind'] = np.where(df['originalParcelCreationTime'].dt.dayofweek.isin([5,6]), 1, 0)\n",
    "b = [0,4,8,12,16,20,24]\n",
    "l = ['Late_Night', 'Early_Morning','Morning','Noon','Eve','Night']\n",
    "df['sessionofday'] = pd.cut(df['hour'], bins=b, labels=l, include_lowest=True)\n",
    "    \n",
    "    \n",
    "le = LabelEncoder()\n",
    "df['trackingEvent.eventCategory'] = le.fit_transform(df['trackingEvent.eventCategory'])\n",
    "df['sessionofday'] = le.fit_transform(df['sessionofday'])\n",
    "    \n",
    "features = df[['trackingEvent.eventCategory', 'trackingEvent.client.clientId',\n",
    "       'trackingEvent.preadviceDetail.deliveryDetails.parcelId','trackingEvent.preadviceDetail.parcelType.parcelTypeId','hour','sessionofday','weekdayind']]\n",
    "target = df[['trackingEvent.preadviceDetail.parcelDetails.numberOfItems']]\n",
    "    \n",
    "# Split data into train and test sets\n",
    "train_size = int(len(df)*0.8)\n",
    "X_train,y_train = features[:train_size],target[:train_size]\n",
    "X_test,y_test = features[train_size:],target[train_size:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96c7713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:42] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-0fc7796c793e6356f-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijaya.sekhar\\Anaconda3\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"xgboost-regressor\"):\n",
    "    # Log XGBoost parameters\n",
    "    params = {\n",
    "     'objective': 'reg:squarederror',\n",
    "     'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "     'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Train XGBoost model\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        evals=[(dtest, \"eval\")],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Log XGBoost model\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8a2487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MLflow experiment and run IDs\n",
    "# experiment_id = mlflow.active_experiment_id()\n",
    "# run_id = mlflow.active_run().info.run_id\n",
    "# save trained model\n",
    "model_path = \"model\"\n",
    "mlflow.sklearn.save_model(model, model_path)\n",
    "mlflow.log_artifact(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33213caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import required libraries\n",
    "# import mlflow\n",
    "\n",
    "# # Define the model name and stage\n",
    "# model_name = \"XGBoost Regressor Model\"\n",
    "# model_stage = \"Production\"\n",
    "\n",
    "# # Register the model in MLflow model registry\n",
    "# with mlflow.start_run(run_name=\"MLflow Model Registry Run\"):\n",
    "#     model_uri = \"runs:/{}/{}\".format(mlflow.active_run().info.run_id, model_name)\n",
    "#     mv = mlflow.register_model(model_uri=model_uri, name=model_name, stage=model_stage)\n",
    "#     print(\"Model version: {}\".format(mv.version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ff4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ZenML pipeline\n",
    "@zenml.Pipeline(name=\"xgboost-regressor-pipeline\")\n",
    "def xgboost_regressor_pipeline():\n",
    "    # Define input data\n",
    "    input_data_step = zenml.steps.InputData(\n",
    "    with open('C:/Users/vijaya.sekhar/Downloads/download/download/EVRI/EVRI/data/evri-nonprod-dgw-firehose-tracking-5-2022-05-05-06 (early morning sample).json') as f:\n",
    "        ps_data = json.load(f)\n",
    "    ps_df = pd.json_normalize(ps_data)\n",
    "    )\n",
    "\n",
    "    # Define split data step\n",
    "    split_data_step = zenml.steps.SplitData(\n",
    "        split_map={\n",
    "            \"train\": {\n",
    "                \"split_expression\": \"lambda df: df.sample(frac=0.8, random_state=1234)\",\n",
    "                \"is_training\": True,\n",
    "            },\n",
    "            \"eval\": {\n",
    "                \"split_expression\": \"lambda df: df.drop(list(filter(lambda col: col != 'target', df.columns)), axis=1, errors='ignore')\",\n",
    "                \"is_training\": False,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Define xgboost step\n",
    "    xgboost_step = zenml.steps.XGBoostRegressor(\n",
    "        max_depth=6, eta=0.1, num_round=100, mlflow=True\n",
    "    )\n",
    "\n",
    "    # Define evaluation step\n",
    "    evaluation_step = zenml.steps.Evaluator(\n",
    "        metrics=[mean_absolute_error, mean_squared_error],\n",
    "        model_name=xgboost_step.name,\n",
    "    )\n",
    "\n",
    "    # Define output step\n",
    "    output_step = zenml.steps.Output(\n",
    "        mode=\"return\",\n",
    "        schema=Schema([(\"mae\", float), (\"mse\", float)]),\n",
    "    )\n",
    "\n",
    "    # Define pipeline\n",
    "    return zenml.Workflow(\n",
    "        input_data=input_data_step,\n",
    "        steps=[split_data_step, xgboost_step, evaluation_step, output_step],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ZenML pipeline\n",
    "pipeline = xgboost_regressor_pipeline().with_mlflow_tracking(\n",
    "    experiment_name=\"xgboost-regressor-pipeline\"\n",
    ")\n",
    "pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d05691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model to Databricks\n",
    "dbutils.fs.mkdirs(\"/mnt/models/xgboost-regressor\")\n",
    "ks.to_csv(test, \"dbfs:/mnt/models/xgboost-regressor/test\")\n",
    "dbutils.fs.mkdirs(\"/mnt/models/xgboost-regressor/model\")\n",
    "mlflow_xgboost = \"runs:/{}/model\".format(run_id)\n",
    "model_dbfs_path = \"/mnt/models/xgboost-regressor/model\"\n",
    "MlflowClient().download_artifacts(mlflow_xgboost, \"xgb.model\", model_dbfs_path)\n",
    "\n",
    "# Load model from DBFS\n",
    "model_path = \"/dbfs/mnt/models/xgboost-regressor/model/xgb.model\"\n",
    "model = mlflow.xgboost.load_model(model_path)\n",
    "\n",
    "# Predict with loaded model\n",
    "test_data = xgb.DMatrix(test.drop(\"target\", axis=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
